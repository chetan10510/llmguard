# ğŸ›¡ï¸ LLMGuard â€“ Prompt Injection + Moderation Toolkit

LLMGuard is a real-time **prompt injection detection and moderation system** for Large Language Models.  
It analyzes incoming prompts, flags unsafe or malicious content, and helps mitigate security risks like **data exfiltration**, **jailbreaking**, and **policy bypass**.  

This project demonstrates **AI safety engineering**, **custom classifier deployment**, and **real-world MLOps practices**.

---

## ğŸš€ Live Demo
ğŸ”— **Try the app here:** [Hugging Face Space](https://huggingface.co/spaces/Tuathe/llmguard)

---

## âœ¨ Features
- **Custom Prompt Injection Classifier** â€“ Trained to detect malicious or policy-violating prompts.
- **Real-time Streamlit Dashboard** â€“ Intuitive UI for testing prompt moderation.
- **Safe/Unsafe Classification** â€“ Instant binary prediction with safety confidence scores.
- **Interactive Moderation History Panel** â€“ Tracks all tested prompts in session.
- **Cloud Deployment** â€“ Fully hosted on Hugging Face Spaces for instant recruiter access.
- **Lightweight Model Wrapper** â€“ Efficient PyTorch + Transformers integration.

---

## ğŸ› ï¸ Tech Stack
- **Frontend/UI:** Streamlit 1.32.0
- **Backend/Inference:** PyTorch, Transformers
- **ML Pipeline:** scikit-learn, NumPy, Pandas
- **Deployment:** Hugging Face Spaces
- **Version Control:** Git + LFS for model weights

---

## ğŸ“‚ Project Structure
ğŸ“ root/
â”œâ”€â”€ app.py # (Optional) Legacy launcher for local dev
â”œâ”€â”€ requirements.txt # Dependencies for Hugging Face build
â”œâ”€â”€ README.md # This file
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ dashboard/
â”‚ â”‚ â””â”€â”€ streamlit_app.py # Streamlit UI
â”‚ â”œâ”€â”€ utils/
â”‚ â”‚ â””â”€â”€ hf_model_wrapper.py # Model load + inference
â”‚ â””â”€â”€ model/
â”‚ â””â”€â”€ infer_classifier.py # (Legacy) Old inference script
â”œâ”€â”€ model/ # Saved fine-tuned model (LFS tracked)

yaml
Copy
Edit

---

## ğŸ“œ Deployment Journey & Failures Overcome

### **Attempt 1 â€“ Local Success, Cloud Failure (Blank Page)**
- Ran perfectly in VS Code with:
  ```bash
  streamlit run app/dashboard/streamlit_app.py
Hugging Face Space loaded a blank screen because the default app_file pointed to app.py at root.

âŒ Root cause: Hugging Face Spaces didnâ€™t know where the Streamlit file was.

âœ… Fix: Added metadata to README.md:

yaml
Copy
Edit
app_file: app/dashboard/streamlit_app.py
sdk: streamlit
sdk_version: 1.32.0
Attempt 2 â€“ Quick Examples Failure
Initial UI included a â€œQuick Examplesâ€ button pulling placeholder examples.

âŒ Root cause: Example list was empty or mismatched format, causing errors.

âœ… Fix: Removed Quick Examples section, simplified UI.

Attempt 3 â€“ Git Push Rejection
First push to Hugging Face failed:

pgsql
Copy
Edit
Updates were rejected because the remote contains work that you do not have locally.
âŒ Root cause: Repo already had remote commits.

âœ… Fix: Used:

bash
Copy
Edit
git pull --rebase origin main
git push origin main --force
Attempt 4 â€“ Dependency Install Failures
Missing dependencies in requirements.txt caused Hugging Face to fail app launch.

âœ… Fix: Added all required packages:

txt
Copy
Edit
streamlit==1.32.0
torch
transformers
scikit-learn
numpy
pandas
ğŸ“Š Resume-Ready Summary
LLMGuard â€“ Prompt Injection + Moderation Toolkit
Built a real-time AI safety tool to detect malicious prompts targeting Large Language Models.
Designed a custom classifier, deployed with Streamlit + PyTorch, and hosted on Hugging Face Spaces.
Overcame multiple deployment failures (app path misconfigurations, dependency issues, Git conflicts) to achieve a fully functional, recruiter-accessible live demo.

ğŸ–¥ï¸ Local Development
bash
Copy
Edit
git clone https://huggingface.co/spaces/Tuathe/llmguard
cd llmguard
pip install -r requirements.txt
streamlit run app/dashboard/streamlit_app.py
